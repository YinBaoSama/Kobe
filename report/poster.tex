%%
%% This is file `tikzposter-template.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% tikzposter.dtx  (with options: `tikzposter-template.tex')
%%
%% This is a generated file.
%%
%% Copyright (C) 2014 by Pascal Richter, Elena Botoeva, Richard Barnard, and Dirk Surmann
%%
%% This file may be distributed and/or modified under the
%% conditions of the LaTeX Project Public License, either
%% version 2.0 of this license or (at your option) any later
%% version. The latest version of this license is in:
%%
%% http://www.latex-project.org/lppl.txt
%%
%% and version 2.0 or later is part of all distributions of
%% LaTeX version 2013/12/01 or later.
%%


\documentclass{tikzposter} %Options for format can be included here

\usepackage{todonotes}

\usepackage[tikz]{bclogo}
\usepackage{lipsum}
\usepackage{amsmath}

\usepackage{booktabs}
\usepackage{longtable}
\usepackage[absolute]{textpos}
\usepackage[it]{subfigure}
\usepackage{graphicx}
\usepackage{cmbright}
%\usepackage[default]{cantarell}
%\usepackage{avant}
%\usepackage[math]{iwona}
\usepackage[math]{kurier}
\usepackage[T1]{fontenc}


%% add your packages here
\usepackage{hyperref}
% for random text
\usepackage{lipsum}
\usepackage[english]{babel}
\usepackage[pangram]{blindtext}

\colorlet{backgroundcolor}{blue!10}

 % Title, Author, Institute
\title{FLIP00 Final Assessment}
\author{Cong Ma}
\institute{$^1$ QingDao Technological University, China \\
}
%\titlegraphic{logos/tulip-logo.eps}

%Choose Layout
\usetheme{Wave}

%\definebackgroundstyle{samplebackgroundstyle}{
%\draw[inner sep=0pt, line width=0pt, color=red, fill=backgroundcolor!30!black]
%(bottomleft) rectangle (topright);
%}
%
%\colorlet{backgroundcolor}{blue!10}

\begin{document}


\colorlet{blocktitlebgcolor}{blue!23}

 % Title block with title, author, logo, etc.
\maketitle

\begin{columns}
 % FIRST column
\column{0.5}% Width set relative to text width

%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%
 %\block{Main Objectives}{
%  	      	\begin{enumerate}
%  	      	\item Formalise research problem by extending \emph{outlying aspects mining}
%  	      	\item Proposed \emph{GOAM} algorithm is to solve research problem
%  	      	\item Utilise pruning strategies to reduce time complexity
%  	      	\end{enumerate}
%%  	      \end{minipage}
%}
%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%


%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%
\block{One-hot Coder}{
      % Many real world applications call for one important function
    \begin{itemize}	
    \item
    One-hot coding is a process of transforming class variables into machine learning algorithms.
    \end{itemize}

  	\begin{description}
  	%\item[Outlying Aspects Mining] aims to identify a subspace
    %The task of \emph{Outlying Aspects Mining}
    \item
    In my opinion,one-hot can process the data,and turn them into binary vector.
    If an attribute has n values, attributes. Only one of
    the N attributes of each sample can be 1, which means that the attribute of the
    sample belongs to this category, and the other extended attributes are 0.

  	\end{description}
}
%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%


%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%
\block{One-hot Coder Shortcoming}{
\begin{itemize}
    %\emph{Group Outlying Aspects Mining}
    \item
      It doesn't work in \emph{logistic regression}. Because logistic regression requires
    variables to be independent of each other. If you have only one attribute that
    needs one hot coding, iff a sample are 1 at the same time, the
    two attributes will be completely related, which will inevitably lead to singular
    Error.
    \item
      That is, nonsingular matrix can't solve the unique solution and get the
    unique model, but you can't delete a certain one hot extension variable of the same attribute.

\end{itemize}

}
%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%


%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%

%\note{Note with default behavior}

%\note[targetoffsetx=12cm, targetoffsety=-1cm, angle=20, rotate=25]
%{Note \\ offset and rotated}

 % First column - second block


%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%
\block{Ensemble learning and Bootstrap sampling}{
   \begin{itemize}	
    \item
    Before we talk about the random forest,there are two ideas we need to know.

   \end{itemize}
  	\begin{description}
  	%\item[Outlying Aspects Mining] aims to identify a subspace
    %The task of \emph{Outlying Aspects Mining}
    \item[Ensemble learning]combines multiple models to form a more accurate model.
    The model involved in the combination is called weak learner.
    These weak learner models are used to predict jointly
    \item[Bootstrap sampling] sdfdsfdsafasfafais to take n samples back in the n samples set to form a data set.
    By the way,If the sample size is large, there is a 0.368 probability
    that each sample will not be selected in the whole sampling process.
  	\end{description}


  	
}
%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%


% SECOND column
\column{0.5}
 %Second column with first block's top edge aligned with with previous column's top.

%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%
\block{Bagging Algorithm}{


%\begin{tikzfigure}%[Overall architecture of \emph{GOAM} algorithm]
%    \missingfigure[figcolor=white]{Testing figcolor}
%\end{tikzfigure}

%  where $G_q$ is the query group,
%  $n$ is the number of compare groups,
%  and $h_{k_s}$ is the histogram representation of $G_k$ in the subspace $s$.

\begin{description}
  	\item
   Based on bootstrap sampling, bagging algorithm can be constructed.
   In this method, the trainine set is sampled several times by
   bootstrap, and a weak learner model is trained with the data set formed
   by each sampling, and several independent weak learners are obtained.
   Finally, the combination of thused to predict. The training process is as follows:
\end{description}
  \begin{itemize}	
    \item
    Cycle, for I = 1,..., t
     \item
    The training sample set is obtained by bootstrap sampling
     \item
    A sample set of H is used to train the model
     \item
     End cycle output model combination
  \end{itemize}

}
%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%
% Second column - first block


%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%
\block{Random Forest}
{
\begin{description}
  	\item
   First, a random forest is composed of multiple decision trees. For the
    classification problet sample will be sent to each decision tree
    for prediction, and then vote. The class with the most votes is the final
    classification result. For regressadasdasdassion problems, the prediction output of
    random forest is the mean value of all decision tree outputs.
    \par

\end{description}

}
%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%


% Second column - second block
%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%

%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%


% Bottomblock
%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%
\colorlet{notebgcolor}{blue!20}
\colorlet{notefrcolor}{blue!20}


%\note[targetoffsetx=8cm, targetoffsety=-10cm,rotate=0,angle=180,radius=8cm,width=.46\textwidth,innersep=.1cm]{
%Acknowledgement
%}

%\block[titlewidthscale=0.9, bodywidthscale=0.9]
%{Acknowledgement}{
%}
%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%

\end{columns}


%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%
%[titleleft, titleoffsetx=2em, titleoffsety=1em, bodyoffsetx=2em,%
%roundedcorners=10, linewidth=0mm, titlewidthscale=0.7,%
%bodywidthscale=0.9, titlecenter]

%\colorlet{noteframecolor}{blue!20}
\colorlet{notebgcolor}{blue!20}
\colorlet{notefrcolor}{blue!20}
%           左右                                            上下
\note[targetoffsetx=-13cm, targetoffsety=-30cm,rotate=0,angle=180,radius=8cm,width=.96\textwidth,innersep=.4cm]
{
\begin{minipage}{0.3\linewidth}
\centering
\includegraphics[width=24cm]{logos/tulip-wordmark.eps}
\end{minipage}
\begin{minipage}{0.5\linewidth}
{ \centering
 Thanks for watching!
}
\end{minipage}
}
%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%


\end{document}

%\endinput
%%
%% End of file `tikzposter-template.tex'.

